# Reddit Tech Ideas Crawler

A sophisticated system designed to crawl, analyze, and retrieve technology-related ideas from Reddit using AI-powered analysis.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+ (âœ… Already installed)
- Reddit API credentials
- Google Gemini API key  
- Pinecone API key

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```
âœ… **Already completed!**

### 2. Configure API Keys

You need to set up three API services:

#### **Reddit API Setup**
1. Go to [https://www.reddit.com/prefs/apps](https://www.reddit.com/prefs/apps)
2. Click "Create App" or "Create Another App"
3. Choose "script" as the app type
4. Note down your `client_id` and `client_secret`

#### **Google Gemini API Setup**
1. Go to [Google AI Studio](https://aistudio.google.com/app/apikey)
2. Create a new API key
3. Copy the API key

#### **Pinecone API Setup**
1. Go to [Pinecone](https://www.pinecone.io/) and create an account
2. Create a new project
3. Get your API key from the dashboard

### 3. Update Configuration

Edit the `key.yaml` file with your API keys:

```yaml
keys: 
  GEMINI: your_gemini_api_key_here
  PINECONE: your_pinecone_api_key_here

reddit:
  client_id: your_reddit_client_id_here
  client_secret: your_reddit_client_secret_here
  username: your_reddit_username_here
  password: your_reddit_password_here
```

### 4. Run the Application

```bash
cd src
python main.py
```

## ğŸ“ Project Structure

```
Reddit-Crawler/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # Main execution script
â”‚   â”œâ”€â”€ ingestion.py           # Reddit data collection
â”‚   â”œâ”€â”€ create_vector_database.py  # Vector DB creation
â”‚   â”œâ”€â”€ search_vector_db.py    # Vector search implementation
â”‚   â”œâ”€â”€ gemini_retrieval.py    # AI analysis integration
â”‚   â””â”€â”€ utils.py              # Utility functions
â”œâ”€â”€ runs/                      # Directory for run outputs (auto-created)
â”œâ”€â”€ subreddits.txt            # List of target subreddits
â”œâ”€â”€ Ideation_Query.txt        # Search queries
â”œâ”€â”€ requirements.txt          # Project dependencies
â”œâ”€â”€ key.yaml                 # Configuration file
â””â”€â”€ README.md               # This file
```

## ğŸ”§ How It Works

1. **Data Collection**: Scrapes posts from subreddits listed in `subreddits.txt`
2. **Vector Database**: Creates embeddings and stores them in Pinecone
3. **Semantic Search**: Searches for relevant posts based on queries in `Ideation_Query.txt`
4. **AI Analysis**: Uses Gemini AI to analyze results and generate insights

## ğŸ“ Configuration Files

- **`subreddits.txt`**: List of subreddits to scrape (one per line)
- **`Ideation_Query.txt`**: Search queries for finding relevant content
- **`key.yaml`**: API keys and configuration

## ğŸ“Š Output

Results are stored in timestamped directories under `runs/`:
- `raw_scrap_results.json`: Raw scraped Reddit data
- `vector_search_results.txt`: Semantic search results
- `gemini_response.txt`: AI-generated insights

## âš¡ Current Status

âœ… Dependencies installed  
âœ… Code fixed for your system  
âš ï¸  **Next Step**: Configure API keys in `key.yaml`  

## ğŸ”‘ Security Note

The current `key.yaml` file contains example/demo keys. **Replace them with your own API keys** before running the application.

## ğŸ› Troubleshooting

- **Import errors**: Make sure you're running from the project root directory
- **API errors**: Verify your API keys are correct and have proper permissions
- **Reddit rate limits**: The script includes built-in rate limiting, but heavy usage may still hit limits

## ğŸ“ Need Help?

If you encounter any issues, check the error messages - they'll guide you to the specific configuration that needs attention. 